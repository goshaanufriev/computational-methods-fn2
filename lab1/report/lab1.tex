% !TeX spellcheck = ru_RU-Russian
\documentclass[12pt, a4paper]{article}

\usepackage[utf8]{inputenc}
\usepackage[T1]{fontenc}
\usepackage[russian]{babel}

\usepackage[oglav, boldsect, eqwhole, figwhole, %
remarks, hyperref, hyperprint]{fn2kursstyle}

\makeatletter
\renewcommand{\@oddhead}{\vbox{Ануфриев Г.А., Брегадзе З.Г. \hfill ФН2-52Б \hrule}}
\makeatother

\begin{document}
	\section*{Ответы на контрольные вопросы}
	\begin{enumerate}
		\item \textbf{Каковы условия применимости метода Гаусса без выбора и с выбором ведущего элемента?}
		
		Пусть СЛАУ задана в матричном виде как $Ax=b$. Тогда главным условием применимости метода Гаусса в обоих упомянутых в вопросе случаях является неравенство нулю определителя матрицы системы: $\det A\neq0$.
		
		Если метод Гаусса применяется без выбора ведущего элемента, то необходимо учитывать следующее условие: $a_{ii}^{(i-1)}\neq0$. Это нужно для того, чтобы избежать деления на ноль и, как следствие, аварийного завершения программы.
		
		В случае выбора главного элемента достаточно неравенства нулю определителя матрицы системы, так как деление производится на наибольший по модулю коэффициент при $a_{ii}$, что обеспечивает устойчивость вычислений.
		
		\item \textbf{Докажите, что если $\det A \neq 0$ , то при выборе главного элемента в столбце среди элементов, лежащих не выше главной диагонали, всегда найдется хотя бы один элемент, отличный от нуля.}
		
		$\Box$ <<От противного>>:
		
		Пусть на $k$-том шаге метода Гаусса все элементы в $k$-том столбце начиная с $k$-того равны нулю. Тогда $k$-тый столбец является линейной комбинацией первых $k-1$ столбцов $\Rightarrow$ определитель матрицы равен нулю. Так как элементарные преобразования не обнуляют определитель, а для ихсодной матрицы $\det A \neq 0$, получим противоречие $\Box$
		
		\item\textbf{В методе Гаусса с полным выбором ведущего элемента
		приходится не только переставлять уравнения, но и менять нумерацию неизвестных. Предложите алгоритм, позволяющий восстановить первоначальный порядок неизвестных.}
		
		Для метода Гаусса с полным выбором ведущего элемента необходимо завести массив перестановок, который будет учитывать порядок переменных в ответе. То есть изначально он может выглядеть так:
		
		$$
		\text{permutations} = [0,1,\dots,n-1].
		$$
		
		Если в ходе работы программы меняются местами $i$-й и $j$-й столбцы, то меняются местами и числа $i$ и $j$ в массиве перестановок. Затем, когда найден вектор решения $\tilde{X}$ с измененным порядком неизвестных, находим $X$ с правильным порядком переменных.
		
		\item \textbf{Оцените количество арифметических операций, требуемых для $QR$-разложения произвольной матрицы $A$ размера $n\times n$.}
		
		 На каждом шаге алгоритма для обнуления поддиагональных элементов столбца $i$ ($i = 0, \dots, n-1$) выполняются следующие действия для каждой строки $j$ ($j = i+1, \dots, n-1$):
		
		\begin{enumerate}
			\item \textbf{Вычисление коэффициентов вращения.}
			Для пары элементов $a_{ii}$ и $a_{ji}$ вычисляются коэффициенты $c$ и $s$:
			
			\begin{equation*}
				c_{ij} = \frac{a_{ii}^{(i)}}{\sqrt{\left(a_{ii}^{(i)}\right)^2 + \left(a_{ji}^{(i)}\right)^2}}, \quad s_{ij} = \frac{a_{ji}^{(i)}}{\sqrt{\left(a_{ii}^{(i)}\right)^2 + \left(a_{ji}^{(i)}\right)^2}}.
			\end{equation*}
			Эта процедура требует \textbf{5 операций}: 2 возведения в квадрат, 1 извлечение квадратного корня, 1 сложение и 2 деления.
			
			\item \textbf{Применение вращения.}
			Вращение применяется к строкам $i$ и $j$ матрицы, начиная с столбца $k = i$ (так как элементы левее уже нулевые) и до столбца $k = n-1$. Для каждого столбца $k$ выполняются операции:
			\[
			\begin{aligned}
				a_{ik} &= c \cdot a_{ik} + s \cdot a_{jk}, \\
				a_{jk} &= -s \cdot a_{ik} + c \cdot a_{jk}, \\
			\end{aligned}
			\]
			Это составляет 4 операции умножения. Для одного вращения $(i, j)$ количество таких элементов равно $(n - i)$.
			\item \textbf{Построение матрицы $Q$.}
			К начальной матрице $Q = I$ применяются те же вращения, что и к матрице $A$. Для каждого вращения $(i, j)$ необходимо обновить две строки матрицы $Q$, причем для каждого столбца $k$ ($k = 0, \dots, n-1$) выполняются 4 операции:
			\[
			\begin{aligned}
				q_{ik} &= c \cdot q_{ik} + s \cdot q_{jk}, \\
				q_{jk} &= -s \cdot q_{ik} + c \cdot q_{jk}, \\
			\end{aligned}
			\]
		\end{enumerate}
		
		\textbf{Общее количество операций складывается из операций на всех шагах.}
		
		\begin{itemize}
			\item Количество вращений: Для каждого столбца $i$ требуется обнулить $(n - i - 1)$ элементов ниже диагонали. Таким образом, общее количество вращений (пар $(i, j)$) равно:
			\[
			\sum_{i=0}^{n-1} (n - i - 1) = \frac{n(n-1)}{2}.
			\]
			
			С учетом операций на вычисление коэффициентов:  $\dfrac{5n(n-1)}{2}.$
			
			\item Операции на применение вращений:
			Для вращения, применяемого к строкам $i$ и $j$, количество операций равно $4(n - i)$.
			Суммируем по всем $i$ и $j$:
			\[
			\sum_{i=0}^{n-1} \sum_{j=i+1}^{n-1} 4(n - i) = 4 \sum_{i=0}^{n-1} (n - i)(n - i - 1).
			\]
			Сделаем замену $k = n - i$. Тогда $i$ меняется от $0$ до $n-1$, а $k$ меняется от $n$ до $1$:
			\[
			4 \sum_{k=1}^{n} k(k - 1) = 4 \sum_{k=1}^{n} (k^2 - k) = 4 \left( \frac{n(n+1)(2n+1)}{6} - \frac{n(n+1)}{2} \right).
			\]
			Упростим выражение:
			\[
			\begin{aligned}
				4 \left( \frac{n(n+1)(2n+1)}{6} - \frac{n(n+1)}{2} \right) &= 4 \left( \frac{n(n+1)(2n+1) - 3n(n+1)}{6} \right) = \\
				= 4 \left( \frac{n(n+1)((2n+1) - 3)}{6} \right) &= 4 \left( \frac{n(n+1)(2n - 2)}{6} \right) = \\
				= 4 \left( \frac{2n(n+1)(n - 1)}{6} \right) & = \frac{4n(n^2 - 1)}{3}.
			\end{aligned}
			\]
			Эта часть имеет порядок $O(n^3)$.
			\item Операции на построение матрицы $Q$:
			Для каждого вращения $(i, j)$ необходимо обновить все $n$ столбцов матрицы $Q$, что требует $4n$ операций:
			\[
			\sum_{i=0}^{n-1} \sum_{j=i+1}^{n-1} 4n = 4n \cdot \frac{n(n-1)}{2} = 2n^2(n-1) = 2n^3 - 2n^2.
			\]
			Эта часть также имеет порядок $O(n^3)$.
		\end{itemize}
		
		Суммируя все вклады:
		\[
		\begin{aligned}
			N &= \frac{4n(n^2 - 1)}{3} + 2n^2(n-1) + \frac{5n(n-1)}{2} \\
			&= \frac{4n^3}{3} - \frac{4n}{3} + 2n^3 - 2n^2 + \frac{5n^2}{2} - \frac{5n}{2} \\
			&= \left(\frac{4}{3} + 2\right)n^3 + \left(-\frac{4}{3} - \frac{5}{2}\right)n + \left(-2 + \frac{5}{2}\right)n^2 \\
			&= \frac{10}{3}n^3 + \frac{1}{2}n^2 - \frac{23}{6}n.
		\end{aligned}
		\]
		
		Таким образом, асимптотическая сложность $QR$-разложения составляет \textbf{$\boldsymbol{O(n^3)}$}.
		
		\item \textbf{Что такое число обусловленности и что оно характеризует? Имеется ли связь между обусловленностью и величиной определителя матрицы? Как влияет выбор нормы матрицы на оценку числа обусловленности?}
		
		Величину
		$$
		\text{cond} A = \|A^{-1}\|\cdot\|A\|
		$$
		называют числом обусловленности матрицы $A$. Матрицы с большим числом обусловленности называются плохо обусловленными, в противном случае --- хорошо обусловленными.
		
		Из оценки $\|\delta x\|\leqslant\|A^{-1}\|\|\delta f\|$ следует, что чем меньше определитель $A$, тем больше определитель $A^{-1}$, а значит, больше постоянная при $|\delta f\|$ и, соответственно, больше влияния погрешностей правой части на погрешности решения.
		
		\item \textbf{Как упрощается оценка числа обусловленности, если матрица является:
		\begin{enumerate}
			\item диагональной;
			\item симметричной;
			\item ортогональной;
			\item положительно определённой;
			\item треугольной?
		\end{enumerate}}
	
	Оценка числа обусловленности вобщем случае:
	\begin{equation*}
		cond A \geqslant \dfrac{|\lambda_{max}|}{|\lambda_{min}|}
	\end{equation*}
	
	\textbf{а)} Для диагональной матрицы: 
	\begin{equation*}
		cond A = \|A^{-1}\|_1 \cdot\|A\|_1 = \max\limits_j \sum\limits_{i = 1}^{n} \dfrac{1}{|a_{ij}|} \cdot \max\limits_j \sum\limits_{i = 1}^{n} |a_{ij}| = \dfrac{\max\limits_{j} |a_{jj}|}{\min\limits_{j} |a_{jj}|}
	\end{equation*}
	Для $\| \cdot \|_\infty$ аналогично.
	
	\textbf{б)} Для симметричной матрицы:
	
	Спектральная норма: 
	\begin{equation*}
		\|A\|_s = \left( \max\limits_j \mu_j \right)^{1/2}, \quad \mu_j - \text{сингулярные числа (собств. зн. матрицы $A^*A$)}.
	\end{equation*}
	Если элементы матрицы вещественные, то $A^*$=$A \Rightarrow \mu_j$ равны квадратам собственных значений $A$, т.е.  $\|A\|_s = \max\limits_j |\lambda_j|$, $\lambda_i$ - собственные значения $A$.
	Для симметричной матрицы существует ортогональное разложение $A = Q D Q^T$, где Q - ортогональная матрица, D - диагональная матрица, состоящая из собственных значений. Тогда $A^{-1} = Q^T D^{-1} Q$.
	\begin{equation*}
		\text{cond} A = \|A^{-1}\|_s\cdot\|A\|_s = \max\limits_j |\lambda_j^{-1}| \cdot \max\limits_j |\lambda_j| = \dfrac{\lambda_{max}}{\lambda_{min}}
	\end{equation*}
	
	\textbf{в)} Для ортогональной матрицы:
	
	Спектральная норма: 
	\begin{equation*}
		\|A\|_s = \left( \max\limits_j \mu_j \right)^{1/2}, \quad \mu_j - \text{сингулярные числа (собств. зн. матрицы $A^*A$)}.
	\end{equation*}
	Для вещественной матрицы $A^*$ = $A^T$, тогда $A^*A$ = $A^T A$ = $I \Rightarrow \mu_j = 1$ $\forall i = 1,...,n$  , получим
	\begin{equation*}
		\text{cond} A = \|A^{-1}\|_s\cdot\|A\|_s =  \|A^{T}\|_s\cdot\|A\|_s  = \left( \max\limits_j \mu_j \right)^{1/2} \left( \max\limits_j \mu_j \right)^{1/2} = \max\limits_j \mu_j  = 1
	\end{equation*}
	
	\textbf{г)} Для положительно определенной матрицы собственные значения положительные, получим:
	\begin{equation*}
		cond A \geqslant \dfrac{\lambda_{max}}{\lambda_{min}}
	\end{equation*}
	
	\textbf{д)} Для треугольной матрицы собственный значения элементы на главной диагонали, получим 
	\begin{equation*}
		cond A \geqslant \dfrac{\max\limits_{i} a_{ii}}{\min\limits_{i} a_{ii}}
	\end{equation*}
		
		\item \textbf{Применимо ли понятие числа обусловленности к вырожденным матрицам?}
		
		Понятие числа обусловленности не применимо к вырожденным матрицам, так как они не имеют обратных. Из выражения для числа обусловленности $$\text{cond} A=\|A\|\cdot\|A^{-1}\|$$ следует, что в таком случае посчитать число обусловленности для вырожденной матрицы невозможно, и его принято считать бесконечностью.
		
		\item \textbf{В каких случаях целесообразно использовать метод Гаусса, а в каких—методы, основанные на факторизации матрицы?}
		
		Метод Гаусса эффективен, когда нужно решить систему с одной правой частью, матрица не имеет специальной структуры (не симметричная, не положительно определенная и т.д.),требуется простота реализации для разовых вычислений.
		
		Методы факторизации целесообразны, когда нужно решить много систем с одной матрицей и разными правыми частями (факторизацию делают один раз), матрица имеет специальные свойства.
		
		\item \textbf{Как можно объединить в одну процедуру прямой и обратный ход метода Гаусса? В чём достоинства и недостатки такого подхода?}
		
		Для того, чтобы объединить прямой и обратный ход метода Гаусса в одну процедуру, можно на каждом шаге прямого хода не только нормировать ведущий элемент, но и занулять остальные элементы этого столбца. Тогда в одном большом цикле мы сможем сразу получить решение системы уравнений.
		
		\textit{Достоинства:}
		\begin{itemize}
			\item решение получено сразу, без использования обратного хода;
			\item интуитивно понятный метод, связанный с элементарными преобразованиями строк матрицы.
		\end{itemize}
		
		\textit{Недостатки:}
		\begin{itemize}
			\item меньше устойчивость численного решения: быстрее накапливается ошибка из-за операций над элементами как под главной диагональю, так и над ней;
			\item большее число операций: требует примерно в 2 раза больше числа арифметических операций по сравнению с методом Гаусса
		\end{itemize}
		
		\item\textbf{Объясните, почему, говоря о векторах, норму $\|\cdot\|_1$ часто называют октаэдрической, норму $\|\cdot\|_2$~--- шаровой, а норму $\|\cdot\|_\infty$~--- кубической.}
		
		\begin{equation*}
			\|x\|_1 = \sum \limits_{i = 1}^n |x_i|, \qquad \|x\|_2 = \left( \sum \limits_{i = 1}^n x_i^2 \right)^{1/2}, \qquad \|x\|_\infty = \max_i |x_i|;
		\end{equation*}
		
		Соотвествующие единичные шары ($\|x\| \le 1$) в данных нормах при изображении в декартовых координатах представляют собой: октаэдр для $\|\cdot\|_1$, шар для~$\|\cdot\|_2$, куб для $\|\cdot\|_\infty$.
		
	\end{enumerate}
	
\end{document}