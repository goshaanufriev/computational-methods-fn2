\documentclass[12pt, a4paper,titlepage]{article}
\usepackage[utf8]{inputenc}
\usepackage[russian]{babel}
\usepackage{float}
\usepackage{subcaption}
\usepackage{siunitx}
\usepackage{amsmath}
\usepackage[oglav, boldsect, eqwhole, figwhole, %
remarks, hyperref, hyperprint]{fn2kursstyle}
\usepackage{multirow}
\usepackage{supertabular}
\usepackage{multicol}
\usepackage{graphicx}
\usepackage{pdfpages}
\usepackage{parskip}  % Улучшает интервалы между параграфами
\setlength{\parskip}{0.5em}  % Настройка интервала
\newcommand{\norm}[1]{\lVert #1 \rVert}

\begin{document}
	\begin{itemize}
		\item{x = Cx + y}
	
		Исходная система линейных уравнений:
		\[
		Ax = b
		\]
		
		Представим матрицу \(A\) в виде разности двух матриц:
		\[
		A = M - N
		\]
		где \(M\) -- легко обратимая матрица.
		
		Подставим это разложение в исходное уравнение:
		\begin{align*}
			&(M - N)x = b \\
			&Mx = Nx + b \\
			&x = M^{-1}Nx + M^{-1}b \quad \\
		\end{align*}
		Введем обозначения:
		\[
		C = M^{-1}N, \quad y = M^{-1}b
		\]
		
		Получим:
		\[
		\boxed{x = Cx + y}
		\]
		\item{\textbf{Сжимающее отображение}}
		
		Метрическое пространство \( (X, \rho) \) называют \textbf{полным} тогда и только тогда, когда в нем любая фундаментальная последовательность сходится к некоторому элементу этого пространства, т.~е. для любой фундаментальной в \( (X, \rho) \) последовательности \(\{x_n\}_{n=1}^\infty \subset X\) существует такой элемент \( x_0 \in X \), что $\lim_{n \to \infty} x_n = x_0.$
		
		\textbf{Принцип сжимающих отображений}. Всякое сжимающее отображение \( g: X \to X \) в \emph{полном} метрическом пространстве \((X, \rho)\) имеет, и притом единственную, неподвижную точку, т.~е. такую точку \( x \in X \), что \( g(x) = x \).
		
		Рассмотрим матрицу:
		\[
		C = \begin{pmatrix}
			0.5 & 2.0 \\
			0.0 & 0.5
		\end{pmatrix}
		\]
		
		Вычислим её нормы:
		\begin{itemize}
			\item 
			\begin{align*}
				\|C\|_1 &= \max\left(\sum_{i=1}^2 |c_{i1}|, \sum_{i=1}^2 |c_{i2}|\right) = \\
				&= \max\left(|0.5| + |0.0|, |2.0| + |0.5|\right) =  \\
				&= \max\left(0.5, 2.5\right) = 2.5
			\end{align*}
			
			\item 
			\begin{align*}
				\|C\|_\infty &= \max\left(\sum_{j=1}^2 |c_{1j}|, \sum_{j=1}^2 |c_{2j}|\right)= \\
				&= \max\left(|0.5| + |2.0|, |0.0| + |0.5|\right) = \\
				&= \max\left(2.5, 0.5\right) = 2.5
			\end{align*}
		\end{itemize}
		Спектральный радиус $\rho(C)$ равен максимальному по модулю собственному значению матрицы $C$.
		
	    Находим собственные значения
		\begin{align*}
			\det(C - \lambda I) &= \det\begin{bmatrix}
				0.5 - \lambda & 2.0 \\
				0.0 & 0.5 - \lambda
			\end{bmatrix} \\
			&= (0.5 - \lambda)(0.5 - \lambda) - (2.0)(0.0) \\
			&= (0.5 - \lambda)^2\\
			\rho(C) &= \max(|\lambda_1|, |\lambda_2|) \\
			&= \max(|0.5|, |0.5|) = 0.5
		\end{align*}
		
		Получили
		\begin{align*}
			\|C\|_1 &= 2.5 > 1 \\
			\|C\|_\infty &= 2.5 > 1 \\
			\rho(C) &= 0.5 < 1
		\end{align*}
		
		\textbf{Вывод:} Хотя матричные нормы $\|C\|_1$ и $\|C\|_\infty$ больше 1, спектральный радиус $\rho(C) = 0.5 < 1$, что гарантирует сходимость итерационного процесса.
		
		
		В нормах $\|\cdot\|_1$ и $\|\cdot\|_\infty$ отображение не является сжимающим.
		
		\item{\textbf{Подбор} $\tau$}
		
		Подбор итерационного параметра $\tau$ для положительно определённой симметричной матрицы
		
		\[
		Ax = b,
		\]
		где $A$ -- положительно определённая симметричная матрица ($A = A^\top > 0$), $b$ -- вектор правой части.
		
		Метод простой итерации для решения этой системы имеет вид:
		\[
		x^{k+1} = x^k - \tau (Ax^k - b),
		\]
		что эквивалентно:
		\[
		x^{k+1} = (I - \tau A)x^k + \tau b.
		\]
		
		Матрица перехода метода:
		\[
		B = I - \tau A.
		\]
		
		Сходимость метода гарантируется, если спектральный радиус $\rho(B) < 1$.
		
		Пусть $\lambda_i$ -- собственные числа матрицы $A$, причём:
		\[
		0 < \lambda_{\min} = \lambda_1 \leq \lambda_2 \leq \dots \leq \lambda_n = \lambda_{\max}.
		\]
		
		Собственные числа матрицы $B$:
		\[
		\mu_i = 1 - \tau\lambda_i.
		\]
		
		Условие сходимости $|\mu_i| < 1$ для всех $i$:
		\[
		-1 < 1 - \tau\lambda_i < 1.
		\]
		
		Получим
		\[
		0 < \tau\lambda_i < 2.
		\]
		
		Таким образом
		\[
		\boxed{0 < \tau < \frac{2}{\lambda_{\max}}}.
		\]
		
		\item{Начаольное приближение}
		
		Выбор вектора правой части в качестве начального приближения в методе простой итерации является эффективной эвристикой по следующим причинам:
		\begin{itemize}
			\item{Физическая интерпретация}
			
			В прикладных задачах правая часть системы обычно соответствует внешним воздействиям (источники тепла, приложенные силы, заряды), а решение — отклику системы на эти воздействия. Поскольку отклик часто соизмерим с воздействием, вектор правой части дает реалистичную оценку масштаба решения.
			
			\item{Математическое обоснование}
			
			Для систем с диагональным преобладанием компоненты решения грубо приближаются как $x_i \approx \dfrac{b}{a_{ii}}$. 
			
			\item{Практические преимущества}
			
			Такой подход быстрее выводит итерационный процесс на значимые значения. Это часто позволяет сократить количество итераций, необходимых для достижения заданной точности, по сравнению с началом из нулевого вектора.
		\end{itemize}
		
		\item{Критерий Останова в методе Зейделя}		

		Рассмотрим систему линейных уравнений:
		\[
		Ax = b
		\]
		После приведения к виду $x = Cx + d$ метод Зейделя записывается как:
		\[
		x^k = C_L x^k + C_U x^{k-1} + d
		\]
		где:
		\begin{itemize}
			\item $C_L$ -- нижняя треугольная часть матрицы $C$ (включая диагональ)
			\item $C_U$ -- строго верхняя треугольная часть матрицы $C$
		\end{itemize}
		
		Критерий остановки имеет вид:
		\[
		\|x^k - x^{k-1}\| < \dfrac{1 - \|C\|}{\|C_U\|} \varepsilon
		\]
		
		Из матричного представления метода Зейделя:
		\[
		x^k = C_L x^k + C_U x^{k-1} + d
		\]
		\[
		x^{k-1} = C_L x^{k-1} + C_U x^{k-2} + d
		\]
		
		Вычитая почленно, получаем:
		\[
		x^k - x^{k-1} = C_L (x^k - x^{k-1}) + C_U (x^{k-1} - x^{k-2})
		\]
		
		Переносим первое слагаемое влево:
		\[
		(I - C_L)(x^k - x^{k-1}) = C_U (x^{k-1} - x^{k-2})
		\]
		
		Следовательно:
		\[
		x^k - x^{k-1} = (I - C_L)^{-1} C_U (x^{k-1} - x^{k-2}) \tag{1}
		\]
		
		Введём погрешность $e^k = x^k - x^*$, где $x^*$ -- точное решение.
		
		Из метода Зейделя для точного решения:
		\[
		x^* = C_L x^* + C_U x^* + d
		\]
		
		Вычитаем из уравнения метода:
		\[
		x^k - x^* = C_L (x^k - x^*) + C_U (x^{k-1} - x^*)
		\]
		\[
		e^k = C_L e^k + C_U e^{k-1}
		\]
		
		Решая относительно $e^k$:
		\[
		(I - C_L)e^k = C_U e^{k-1}
		\]
		\[
		e^k = (I - C_L)^{-1} C_U e^{k-1} \tag{2}
		\]
		
		
		Из уравнения (1) и (2) видим, что разность итераций и погрешность связаны через одну и ту же матрицу $(I - C_L)^{-1} C_U$.
		
		Рассмотрим разность:
		\[
		e^k - e^{k-1} = (x^k - x^*) - (x^{k-1} - x^*) = x^k - x^{k-1}
		\]
		
		С другой стороны:
		\[
		e^k - e^{k-1} = (I - C_L)^{-1} C_U e^{k-1} - e^{k-1}
		= [(I - C_L)^{-1} C_U - I] e^{k-1}
		\]
		
		После преобразований получаем  оценку:
		\[
		\|e^k\| \leq \frac{\|C_U\|}{1 - \|C\|} \|x^k - x^{k-1}\| \tag{3}
		\]
		
		
		Мы хотим обеспечить $\|Ax^k - b\| < \varepsilon$. 
		
		Учитывая, что:
		\[
		\|Ax^k - b\| = \|A(x^k - x^*)\| = \|A e^k\| \leq \|A\|\|e^k\|
		\]
		
		Из оценки (3) достаточно потребовать:
		\[
		\|A\| \cdot \frac{\|C_U\|}{1 - \|C\|} \|x^k - x^{k-1}\| < \varepsilon
		\]
		
		Отсюда:
		\[
		\|x^k - x^{k-1}\| < \frac{1 - \|C\|}{\|A\|\|C_U\|} \varepsilon
		\]
		
		В частном случае, когда $\|A\| = 1$ или после соответствующего масштабирования, получаем окончательный критерий:
		\[
		\|x^k - x^{k-1}\| < \dfrac{1 - \|C\|}{\|C_U\|} \varepsilon
		\]
		
		Заключение
		
		Норма $\|C_U\|$ в знаменателе возникает из-за структуры метода Зейделя, где верхняя треугольная часть матрицы $C$ отвечает за использование "старых" компонент решения на текущей итерации. Коэффициент $\frac{1 - \|C\|}{\|C_U\|}$ обеспечивает гарантированную точность решения по невязке через контролируемую разность последовательных приближений.
	\end{itemize}
\end{document}